# -*- coding: utf-8 -*-
"""General utility/helpers."""
import json
import logging
import os
from typing import Any
from typing import Dict
from typing import Iterable
from typing import List
from typing import Optional
from typing import Union
from uuid import UUID

from mantarray_waveform_analysis import CONTRACTION_TIME_UUID
from mantarray_waveform_analysis import RELAXATION_TIME_UUID
from mantarray_waveform_analysis import TIME_DIFFERENCE_UUID
from mantarray_waveform_analysis import WIDTH_FALLING_COORDS_UUID
from mantarray_waveform_analysis import WIDTH_RISING_COORDS_UUID
from mantarray_waveform_analysis import WIDTH_UUID

from .plate_recording import PlateRecording

logger = logging.getLogger(__name__)


def create_xlsx_for_all_recordings(root_directory: str = ".") -> None:
    """Traverses subdirectories to analyze multiple recordings.

    Assumes that any folder with an H5 file in it has only H5 files from a single recording.

    For simple usage, navigate to the root folder you want to analyze, and run:
    ``python3 -c "from curibio.sdk import check_if_latest_version, create_xlsx_for_all_recordings; check_if_latest_version(); create_xlsx_for_all_recordings()"``

    Args:
        root_directory: where to start the search. Output excel files will all be created in this folder
    """
    list_of_dirs: List[str] = list()
    for root, _, files in os.walk(root_directory):
        if any(file_name.endswith(".h5") for file_name in files):
            list_of_dirs.append(root)
    list_of_dirs = sorted(list_of_dirs)  # ensure deterministic ordering for test suite
    total_recording_count = len(list_of_dirs)
    log_text = f"Analysis of the directory {os.path.abspath(root_directory)} completed. {total_recording_count} total recording directories located."
    logger.info(log_text)
    for idx, iter_dir in enumerate(list_of_dirs):
        log_text = f"Analyzing recording {idx+1} of {total_recording_count}: {os.path.abspath(iter_dir)}"
        logger.info(log_text)
        iter_recording = PlateRecording.from_directory(iter_dir)

        for recording in iter_recording:
            recording.write_xlsx(root_directory)

            # pylint:disable=protected-access # TODO (Eli 3/19/21): There were odd errors in Windows CI about files not being closed in the temp directory and so they couldn't be deleted, so temporarily putting in this patch
            for iter_h5_file in recording._files:
                iter_h5_file._h5_file.close()

        # del iter_recording  # Eli (3/19/21): Resolve windows error with closing file when it is still open


def serialize_main_dict(per_twitch_dict: Dict[int, Any], metrics_to_create: Iterable[UUID]) -> Dict[str, Any]:
    """Serialize a per-twitch-dict for saving as JSON.

    Args:
    per_twitch_dict: dictionary of per-twitch values as generated by `mantarray_waveform_analysis.peak_detection.data_metrics`
    metrics_to_create: list of UUID metrics

    Returns:
    serialized: dictionary of serialized per-twitch values
    """
    # initialize serialized dictionary
    serialized: Dict[
        str,
        Dict[
            str,
            Any,
        ],
    ] = dict()

    serialized = {
        str(int(twitch)): {str(metric): None for metric in metrics_to_create}
        for twitch in per_twitch_dict.keys()
    }

    def add_metric(twitch: int, metric: UUID) -> Union[str, Dict[str, Any]]:

        # get current per_twitch_metric dictionary
        temp_metric_dict = per_twitch_dict[twitch][metric]

        if metric in [TIME_DIFFERENCE_UUID]:

            time_diff: Dict[str, Dict[str, str]] = dict()
            time_diff = {str(perc): dict() for perc in range(10, 95, 5)}

            for twitch_width_perc in range(10, 95, 5):

                temp_width_dict = temp_metric_dict[twitch_width_perc]
                time_diff[str(twitch_width_perc)] = dict(
                    zip(
                        map(str, temp_width_dict.keys()),
                        map(str, [temp_width_dict[submetric] for submetric in temp_width_dict.keys()]),
                    )
                )

            return time_diff

        if metric in [WIDTH_UUID]:

            widths: Dict[str, Dict[str, Any]] = dict()
            widths = {str(perc): dict() for perc in range(10, 95, 5)}

            for twitch_width_perc in range(10, 95, 5):

                temp_width_dict = temp_metric_dict[twitch_width_perc]
                per_perc_width_dict: Dict[str, Union[str, List[str]]]
                per_perc_width_dict = {str(key): list() for key in temp_width_dict.keys()}

                for key, value in temp_width_dict.items():
                    if key in [WIDTH_RISING_COORDS_UUID, WIDTH_FALLING_COORDS_UUID]:
                        per_perc_width_dict[str(key)] = list(map(str, value))
                    else:
                        per_perc_width_dict[str(key)] = str(value)

                widths[str(twitch_width_perc)] = per_perc_width_dict
            return widths

        temp = str(per_twitch_dict[twitch][metric])

        return temp

    # iterate over twitches
    for twitch in per_twitch_dict.keys():
        # iterate over metrics
        for metric in metrics_to_create:
            serialized[str(int(twitch))][str(metric)] = add_metric(twitch, metric)

    return serialized


def deserialize_main_dict(json_file: str, metrics_to_create: Iterable[UUID]) -> Dict[int, Any]:
    """De-serialize a per-twitch-dict after loading from JSON.

    Args:
    json_file: saved serialized dictionary
    metrics_to_create: list of UUID metrics

    Returns:
    serialized: dictionary of de-serialized per-twitch values
    """
    with open(json_file, "r") as file_object:
        serialized = json.load(file_object)

    twitches = serialized.keys()
    deserialized: Dict[
        int,
        Dict[
            UUID,
            Any,
        ],
    ] = dict()
    deserialized = {int(twitch): {metric: None for metric in metrics_to_create} for twitch in twitches}

    def add_metric(twitch: int, metric: UUID) -> Union[float, Dict[int, Any]]:

        twitch_dict = serialized[twitch]

        # get dictionary associated with specific metrics
        temp_metric_dict = twitch_dict[str(metric)]

        if metric in [TIME_DIFFERENCE_UUID]:

            time_diffs: Dict[int, Dict[UUID, float]]
            time_diffs = {perc: dict() for perc in range(10, 95, 5)}

            # iterate over twitch_widths
            for twitch_width_perc in range(10, 95, 5):

                # get dictionary associated with twitch width
                temp_width_dict = temp_metric_dict[str(twitch_width_perc)]

                keys = map(UUID, temp_width_dict.keys())
                values = map(float, [temp_width_dict[submetric] for submetric in temp_width_dict.keys()])
                time_diffs[int(twitch_width_perc)] = dict(zip(keys, values))

            return time_diffs

        if metric in [WIDTH_UUID]:

            widths: Dict[int, Dict[UUID, Union[float, List[float]]]]
            widths = {perc: dict() for perc in range(10, 95, 5)}

            # iterate over twitch_widths
            for twitch_width_perc in range(10, 95, 5):

                # get dictionary associated with twitch width
                temp_width_dict = temp_metric_dict[str(twitch_width_perc)]
                per_perc_width_dict: Dict[UUID, Any]
                per_perc_width_dict = {UUID(key): tuple() for key in temp_width_dict.keys()}

                for key, value in temp_width_dict.items():

                    if key in map(str, [WIDTH_RISING_COORDS_UUID, WIDTH_FALLING_COORDS_UUID]):
                        per_perc_width_dict[UUID(key)] = tuple(map(float, value))
                    else:
                        per_perc_width_dict[UUID(key)] = float(value)

                widths[twitch_width_perc] = per_perc_width_dict

            return widths

        return float(temp_metric_dict)

    # iterate over twitches
    for twitch in serialized.keys():
        # iterate over metrics
        for metric in metrics_to_create:
            deserialized[int(twitch)][metric] = add_metric(twitch, metric)
    return deserialized


def serialize_aggregate_dict(
    aggregate_dict: Dict[UUID, Any], metrics_to_create: Iterable[UUID]
) -> Dict[str, Any]:
    """Serialize a per-twitch-dict for saving as JSON.

    Args:
    per_twitch_dict: dictionary of per-twitch values as generated by `mantarray_waveform_analysis.peak_detection.data_metrics`
    metrics_to_create: list of UUID metrics

    Returns:
    serialized: dictionary of serialized per-twitch values
    """
    estimates = ["n", "mean", "std", "min", "max"]

    def by_twitch_width(temp_metric: UUID) -> Dict[str, Any]:

        temp_metric_dict = aggregate_dict[temp_metric]
        by_width: Dict[str, Dict[str, Any]]
        by_width = {str(perc): {str(estimate): None for estimate in estimates} for perc in range(10, 95, 5)}

        for twitch_width_perc in range(10, 95, 5):
            for estimate in estimates:
                by_width[str(twitch_width_perc)][str(estimate)] = str(
                    temp_metric_dict[twitch_width_perc][estimate]
                )

        return by_width

    serialized = {}
    for metric in metrics_to_create:

        if metric == TIME_DIFFERENCE_UUID:
            for sub_metric in [RELAXATION_TIME_UUID, CONTRACTION_TIME_UUID]:
                serialized[str(sub_metric)] = by_twitch_width(sub_metric)

        elif metric == WIDTH_UUID:
            serialized[str(metric)] = by_twitch_width(metric)

        else:

            temp = {str(estimate): str(aggregate_dict[metric][estimate]) for estimate in estimates}
            serialized[str(metric)] = temp

    return serialized


def deserialize_aggregate_dict(json_file: str, metrics_to_create: Iterable[UUID]) -> Dict[UUID, Any]:
    """De-serialize an aggreagate-dict after loading from JSON.

    Args:
    json_file: saved serialized dictionary
    metrics_to_create: list of UUID metrics

    Returns:
    serialized: dictionary of de-serialized aggregate metrics
    """
    deserialized: Dict[
        UUID,
        Dict[
            Union[str, int],
            Any,
        ],
    ] = dict()
    deserialized = {}

    with open(json_file, "r") as file_object:
        serialized = json.load(file_object)

    estimates = ["n", "mean", "std", "min", "max"]

    # python can't cast "None" string to None, so we add this
    def str_to_float(input_string: str) -> Optional[float]:

        return None if input_string == "None" else float(input_string)

    def by_twitch_width(temp_metric: UUID) -> Dict[Union[str, int], Any]:

        temp_metric_dict = serialized[str(temp_metric)]
        by_width: Dict[Union[str, int], Any]
        by_width = {perc: {str(estimate): None for estimate in estimates} for perc in range(10, 95, 5)}

        for twitch_width_perc in range(10, 95, 5):
            for estimate in estimates:
                by_width[twitch_width_perc][str(estimate)] = float(
                    temp_metric_dict[str(twitch_width_perc)][str(estimate)]
                )

        return by_width

    for metric in metrics_to_create:

        if metric == TIME_DIFFERENCE_UUID:
            for sub_metric in [RELAXATION_TIME_UUID, CONTRACTION_TIME_UUID]:
                deserialized[sub_metric] = by_twitch_width(sub_metric)

        elif metric == WIDTH_UUID:
            deserialized[metric] = by_twitch_width(metric)

        else:

            temp: Dict[Union[str, int], Any]
            temp = {estimate: str_to_float(serialized[str(metric)][(estimate)]) for estimate in estimates}
            deserialized[metric] = temp

    return deserialized
