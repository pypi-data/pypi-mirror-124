# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/Client.ipynb (unless otherwise specified).

__all__ = ["Client", "DataSource", "ProgressStatus", "Model", "Prediction"]

# Internal Cell

""" Client module

    This module encapsulates all classes conncted to the API service.

"""

# Cell

from typing import *

# Internal Cell

import os
from time import sleep
import requests
from datetime import datetime, timedelta

import pandas as pd
from tqdm import tqdm

from fastcore.foundation import patch, patch_to

from .logger import get_logger, set_level

# Internal Cell

logger = get_logger(__name__)

# Internal Cell


def _ensure_is_instance(o: Any, cls: Type):
    """A function to check if the object argument is an instance of the class argument.

    Args:
        o: A python object for which the instance needs to be checked.
        cls: The expected instance of the object argument.

    Raises:
        A TypeError if the object is not an instance of the class type.
    """
    if not isinstance(o, cls):
        raise TypeError(
            f"The parameter must be a {cls} type, but got `{type(o).__name__}`"
        )


# Internal Cell


def _get_json(response: requests.Response) -> Dict[str, Any]:
    """A function to validate the status of the response object.

    Args:
        response: The response object that encapsulates the server's response.

    Returns:
        A dictionary of the response body.

    Raises:
        ValueError: If the response code is not in range of 200 - 399.
    """
    if response:
        return response.json()
    else:
        raise ValueError(response.json()["detail"])


# Internal Cell


def _post_data(
    url: str,
    data: Optional[Dict[str, Any]],
    token: Optional[str],
) -> Dict[str, Any]:
    """A function to send a POST request.

    Args:
        url: The URL of the server to which the request needs to be sent.
        data: A Dictionary object to send in the body of the POST request.
        token: The unique auth token for the client, obtained via calling the `Client.authenticate` method.
            Set it to `None` in `Client.authenticate()` to obtain the token.

    Returns:
        A dictionary that encapsulates the response body.

    Raises:
        ConnectionError: If the server is not reachable.
        ValueError: If the response code is not in range of 200 - 399.
    """
    if token is not None:
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.post(url, json=data, headers=headers)
    else:
        response = requests.post(url, data=data)
    return _get_json(response)


# Internal Cell


def mask(s: str) -> str:
    return "*" * len(s)


# Internal Cell


def _get_data(url: str, token: Optional[str]) -> Dict[str, Any]:
    """Send a GET request.

    Args:
        url: The URL of the server to which the request needs to be sent.
        token: The unique auth token for the client, obtained via calling the `Client.authenticate` method.

    Returns:
        A dictionary that encapsulates the response body.

    Raises:
        ConnectionError: If the server is not reachable.
        ValueError: If the response code is not in range of 200 - 399.
    """
    headers = {"Authorization": f"Bearer {token}"}
    response = requests.get(url, headers=headers)
    return _get_json(response)


# Internal Cell


def _delete(url: str, token: Optional[str]) -> Dict[str, Any]:
    """Send a DELETE request.

    Args:
        url: The URL of the server to which the request needs to be sent.
        token: The unique auth token for the client, obtained via calling the `Client.authenticate` method.

    Returns:
        A dictionary that encapsulates the response body.

    Raises:
        ConnectionError: If the server is not reachable.
        ValueError: If the response code is not in range of 200 - 399.
    """
    headers = {"Authorization": f"Bearer {token}"}
    response = requests.delete(url, headers=headers)
    return _get_json(response)


# Cell


class Client:
    """A class for authenticating and accessing the airt service.

    Before you can use the service, you must acquire a username and password for your developer account. Please contact us by email info@airt.ai to get one.

    The username, password, and server address can be passed explicitly while calling the `authenticate` method in the `Client` class, or stored
    in environment variables `AIRT_SERVICE_USERNAME`, `AIRT_SERVICE_PASSWORD`, and `AIRT_SERVER_URL` respectively.

    Upon successful authentication, the airt services will be available.
    """

    server: Optional[str] = None
    auth_token: Optional[str] = None

    def __init__(self, server: str, auth_token: str):
        Client.server = server
        Client.auth_token = auth_token

    @classmethod
    def authenticate(
        cls, *, username: str = None, password: str = None, server: str = None
    ):
        """A class method to authenticate and validate the developer token for accessing the airt services.

        The authenticate method calls the AIRT services for validating the given username and password. Upon successful
        authentication, an auth token will be returned and will be implicitly used in all the subsequent interactions with the server.

        Args:
            username: Username for your developer account. If not set (default value `None`), it will try to
                use the value from environment variable `AIRT_SERVICE_USERNAME`.
            password: Password for your developer account. If not set (default value `None`), it will try to
                use the value from environment variable `AIRT_SERVICE_PASSWORD`.
            server: Server address used to connect to. If not set (default value `None`), it will try to
                use the value from environment variable `AIRT_SERVER_URL`. If the variable is not set as well,
                then the default public server will be used. You should leave this to default value unless you
                are running your own server (please contact us for that possibility by email info@airt.ai).

        Raises:
            ValueException: If the `username`/`password` pair does not match the one for sevice hosted at `server`.
            ConnectionError: If the server address is invalid or not reachable.
            KeyError: if username or password are None and there are not stored in environment variables

        """
        env_airt_service_username = "AIRT_SERVICE_USERNAME"
        env_airt_service_password = "AIRT_SERVICE_PASSWORD"
        env_airt_service_address = "AIRT_SERVER_URL"
        airt_prod_server_URI = "https://api.airt.ai"

        cls.server = (
            server
            if server is not None
            else os.environ.get(env_airt_service_address, airt_prod_server_URI)
        )

        response = _post_data(
            url=f"{cls.server}/token",
            data=dict(
                username=(
                    username
                    if username is not None
                    else os.environ[env_airt_service_username]
                ),
                password=(
                    password
                    if password is not None
                    else os.environ[env_airt_service_password]
                ),
            ),
            token=None,
        )
        cls.auth_token = response["access_token"]

    @classmethod
    def _get_server_url_and_token(cls) -> Tuple[Optional[str], Optional[str]]:
        """Fetch the server URL and the auth token.

        Returns:
            A tuple containing server URL and auth token.
        """
        return cls.server, cls.auth_token

    @classmethod
    def post_data(
        cls, relative_url: str, data: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Make a POST request.

        This method will implicitly add the server base URL and the token for every request.

        Args:
            relative_url: The relative URL of the server's API endpoint.
            data: A Dictionary object to send in the body of the POST request.

        Returns:
            Response body as a dictionary.

        Raises:
            ConnectionError: If the server is not reachable.
            ValueError: If the response code is not in range of 200 - 399.
        """
        return _post_data(
            url=f"{cls.server}{relative_url}",
            data=data,
            token=cls.auth_token,
        )

    @classmethod
    def get_data(cls, relative_url: str) -> Dict[str, Any]:
        """Make a GET request.

        This method will implicitly add the server base URL and the token for every request.

        Args:
            relative_url: The relative URL of the API endpoint.

        Returns:
            A dictionary that encapsulates the response body.

        Raises:
            ConnectionError: If the server is not reachable.
            ValueError: If the response code is not in range of 200 - 399.
        """

        return _get_data(url=f"{cls.server}{relative_url}", token=cls.auth_token)

    @classmethod
    def delete_data(cls, relative_url: str) -> Dict[str, Any]:
        """Make a DELETE request.

        This method will implicitly add the server base URL and the token for every request.

        Args:
            relative_url: The relative URL of the API endpoint.

        Returns:
            A dictionary that encapsulates the response body.

        Raises:
            ConnectionError: If the server is not reachable.
            ValueError: If the response code is not in range of 200 - 399.
        """

        return _delete(url=f"{cls.server}{relative_url}", token=cls.auth_token)


# Internal Cell


def _generate_df(items: Dict[str, Any], columns: list) -> pd.DataFrame:
    """Generate a DataFrame based on the items length

    Args:
        items: A list encapsulating the response from an API endpoint that needs to be converted into a DataFrame.
        columns: A list of columns names to be included in the DataFrame.

    Returns:
        A DataFrame with a shape of (items, columns), if the length of the items is > 0, otherwise an empty DataFrame with only columns names.
    """

    if len(items) > 0:
        df = pd.DataFrame(items)[columns]
    else:
        df = pd.DataFrame({c: [] for c in columns})

    return df


# Internal Cell


def _add_ready_column(df: pd.DataFrame) -> pd.DataFrame:
    """Add ready column to the DataFrame

    Args:
        df: A pandas DataFrame with completed_steps and total_steps columns

    Returns:
        A pandas DataFrame with ready column
    """

    df["ready"] = df["completed_steps"] == df["total_steps"]
    return df.drop(columns=["completed_steps", "total_steps"])


# Cell


class DataSource:
    """A class for encapsulating the data from sources like AWS S3 bucket or a database.

    The DataSource class is automatically instantiated by calling either the s3 or the db static methods of a DataSource class.
    Currently, it is the only way to instantiate this class.

    Currently, we support reading and pushing the data to:

    - a MySql database, and

    - an AWS S3 bucket in the Parquet file format.

    We plan to add other databases and storage mediums in the future.

    For establishing the connection to the MySql database, parameters like host, port,
    database name, table name needs are required.

    And for establishing a connection to the S3 bucket, URI to the target parquet file
    is required.

    In case if access to the database requires authentication, the required username and
    password for the database are automatically read from either the environment variables
    `AIRT_CLIENT_DB_USERNAME` and `AIRT_CLIENT_DB_PASSWORD` or from the username and password
    parameters that are passed to the `DataSource.db` function.

    All the function calls to the library are asynchronous and they return immediately.
    To manage completion, all methods inside the returned object will return a status object
    and a method to display an interactive progress bar that can be called to check the progress.

    Below are code examples for accessing the above methods:

    An example to check for the status flag of s3 connection:

    ```python
    data_source_s3 = DataSource.s3(
        uri="s3://bucket/events.parquet"
    )
    status = data_source_s3.pull()
    status.is_ready()
    ```

    An example to display an interactive progress bar of s3 connection:

    ```python
    data_source_s3 = DataSource.s3(
        uri="s3://bucket/events.parquet"
    )
    data_source_s3.pull().progress_bar()
    ```

    """

    def __init__(
        self,
        data_id: int,
    ):
        """Constructs a new DataSource instance.

        Warning:
            Do not construct this object directly by calling the constructor, please use `DataSource.db()` or `DataSource.s3()` function instead.

        Args:
            data_id: ID of the data in the airt service.
        """
        self.id = data_id

    @staticmethod
    def s3(
        *,
        uri: str = None,
        access_key: str = None,
        secret_key: str = None,
    ) -> "DataSource":
        """Create and return an object that encapsulates the data from a AWS S3 bucket.

        Args:
            uri: The AWS S3 bucket location of the Parquet files as a string.
            access_key: The access key for the S3 bucket. If `None` (default value), then the value
                of environment variable `AWS_ACCESS_KEY_ID` is used.
            secret_key: The secret key for the S3 bucket. If `None` (default value), then the value
                of environment variable `AWS_SECRET_ACCESS_KEY` is used.

        Returns:
            An instance of the `DataSource` class. For more information on the methods that are available in
            the returned object, please check the documentation of the `DataSource` class.

        Raises:
            ValueError: If the parameters `client` and `URI` are empty or None.
            ValueError: If the input parameters to the API are invalid.
            ConnectionError: If the server address is invalid or not reachable.

        An example function call to the DataSource.s3:

        ```python
            data_source_s3 = DataSource.s3(
                uri="s3://bucket/events.parquet"
            )
        ```
        """
        _ensure_is_instance(uri, str)

        access_key = (
            access_key if access_key is not None else os.environ["AWS_ACCESS_KEY_ID"]
        )
        secret_key = (
            secret_key
            if secret_key is not None
            else os.environ["AWS_SECRET_ACCESS_KEY"]
        )
        response = Client.post_data(
            relative_url="/data/s3",
            data=dict(uri=uri, access_key=access_key, secret_key=secret_key),
        )

        return DataSource(data_id=response["id"])

    @staticmethod
    def db(
        *,
        host: str,
        database: str,
        table: str,
        port: Optional[int] = 3306,
        engine: Optional[str] = "mysql",
        username: Optional[str] = None,
        password: Optional[str] = None,
    ) -> "DataSource":
        """Create and return an object that encapsulates the data from a database.

        A static method that creates and returns an object that encapsulates the data
        from a database. In case if access to the database requires authentication,
        the username and password will be read either from the arguments or in the airt
        environment variables.

        The objects created by calling this method won't establish the connection yet.

        Args:
            host: The name of the remote database host machine.
            database: The logical name of the database to establish the connection.
            table: The name of the table in the database.
            port: The port for the database server. If the value is not passed then the
                default port number will be used (e.g. for MySQL, 3306 will be used).
            engine: The name of the database engine. If the value is not passed
                then the default database engine for MySQL will be used.
            username: A valid database user name. If not set (default value `root`),
                it will try to use the value from environment variable `AIRT_CLIENT_DB_USERNAME`.
            password: The password for the specified user. If not set (default value ``),
                it will try to use the value from environment variable `AIRT_CLIENT_DB_PASSWORD`.

        Returns:
            An instance of the `DataSource` class. For more information on the methods that
            are available in the returned object, please check the documentation of the
            `DataSource` class.

        Raises:
            ValueError: If the requred parameters are empty or None.
            ValueError: If the requred parameters to the API are invalid.
            ConnectionError: If the server address is invalid or not reachable.

        An example function call to the DataSource.db:

        ```python
        data_source = DataSource.db(
            host="db.staging.airt.ai",
            database="test",
            table="events"
        )
        ```
        """

        _ensure_is_instance(host, str)
        _ensure_is_instance(database, str)
        _ensure_is_instance(table, str)

        username = (
            username
            if username is not None
            else os.environ.get("AIRT_CLIENT_DB_USERNAME", "root")
        )

        password = (
            password
            if password is not None
            else os.environ.get("AIRT_CLIENT_DB_PASSWORD", "")
        )

        req_data = dict(
            host=host,
            port=port,
            username=username,
            password=password,
            database=database,
            table=table,
            database_server=engine,
        )

        response = Client.post_data(relative_url=f"/data/db", data=req_data)

        return DataSource(data_id=response["id"])

    @staticmethod
    def _get_columns() -> list:
        """Returns the list of columns to be added to the DataFrame."""

        return [
            "id",
            "type",
            "created",
            "completed_steps",
            "total_steps",
            "no_of_rows",
            "folder_size",
        ]

    @staticmethod
    def ls(offset: Optional[int] = 0, limit: Optional[int] = 100) -> pd.DataFrame:
        """Display the list of available datasources.

        Args:
            offset: The number of rows to offset at the beginning of the datasource
                list from the server.If `None`, then the default value `0` will be used.
            limit: The maximum number of rows to return from the server. If `None`,
                then the default value `100` will be used.

        Returns:
            A pandas dataframe with the list of available datasources.

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to list the available datasources:

        ```python
        DataSource.ls()
        ```
        """

        logger.info("ls():")
        logger.info(f" offset =  {offset}")
        logger.info(f" limit =  {limit}")

        _ensure_is_instance(offset, int)
        _ensure_is_instance(limit, int)

        lists = Client.get_data(relative_url=f"/data/?offset={offset}&limit={limit}")

        columns = DataSource._get_columns()

        lists_df = _generate_df(lists, columns)

        return _add_ready_column(lists_df)

    @staticmethod
    def details(data_id: int) -> pd.DataFrame:
        """Return details of a data source

        Args:
            data_id: The id of the data in the airt service.

        Returns:
            A pandas dataframe with the details of the data source.

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to get details of a data source (id=1) from airt service:

        ```python
        DataSource.details(data_id=1)
        ```
        """
        _ensure_is_instance(data_id, int)

        details = Client.get_data(relative_url=f"/data/{data_id}")

        additional_cols = ["user_id", "error", "disabled"]

        columns = DataSource._get_columns() + additional_cols

        details_df = pd.DataFrame(details, index=[0])[columns]

        return _add_ready_column(details_df)

    @staticmethod
    def delete(data_id: int) -> pd.DataFrame:
        """Delete a datasource from airt service

        Args:
            data_id: The id of the data in the airt service.

        Returns:
            A pandas DataFrame encapsulating the details of the deleted data id

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to delete a data source (id=1) from airt service:

        ```python
        DataSource.delete(data_id=1)
        ```
        """
        _ensure_is_instance(data_id, int)

        response = Client.delete_data(relative_url=f"/data/{data_id}")

        columns = DataSource._get_columns()

        datasource_df = pd.DataFrame(response, index=[0])[columns]

        return _add_ready_column(datasource_df)

    @property
    def dtypes(self) -> pd.DataFrame:
        """Return the data type of each column for a data source.

        Returns:
            A pandas dataframe that contains the column names and its data types.

        Raises:
            ValueError: If the input parameters to the API are invalid.
            ConnectionError: If the server address is invalid or not reachable.

        An example to check the dtypes of the connected datasource:

        ```python
        data_source_s3 = DataSource.s3(
            uri="s3://bucket/events.parquet"
        )
        data_source_s3.pull().progress_bar()
        data_source_s3.dtypes
        ```
        """
        dtypes = Client.get_data(relative_url=f"/data/{int(self.id)}/dtypes")
        return pd.DataFrame(dtypes, index=[0])

    def pull(self) -> "ProgressStatus":
        raise NotImplementedError()

    def head(self) -> pd.DataFrame:
        raise NotImplementedError()

    def train(
        self,
        *,
        client_column: str,
        timestamp_column: Optional[str] = None,
        target_column: str,
        target: str,
        predict_after: timedelta,
    ) -> "Model":
        raise NotImplementedError()

    def push(self, predictions: "Prediction") -> Dict[str, int]:
        raise NotImplementedError()


# Cell


class ProgressStatus:
    """A base class for querying status of a remote operation"""

    def __init__(self, relative_url: str):
        """Constructs a new ProgressStatus instance.

        Warning:
            Do not construct this object directly by calling the constructor, please use `DataSource.pull()` or `DataSource.train()` or `Modal.predict()` functions instead.

        Args:
            relative_url: The relative URL to the rest API endpoint.
        """
        self.relative_url = relative_url

    def is_ready(self) -> bool:
        """A function to check if the method's progress is completed.

        Returns:
            True if the progress if completed, else False.
        """
        response = Client.get_data(relative_url=self.relative_url)
        return response["completed_steps"] == response["total_steps"]

    def progress_bar(self, sleep_for: Union[int, float] = 5, timeout: int = 0):
        """Blocks execution while waiting for remote action to be completed and displays a progress bar indicating the completion status.

        Args:
            sleep_for: The time interval in seconds between successive API calls to ping the server for fetching the completed steps.
            timeout: The maximum time allowed in seconds for the asynchronous call to complete the process. If the timeout
                exceeds and the process is yet to complete, then the progress_bar will be terminated.

        Raises:
            TimeoutError: in case of timeout

        """
        total_steps = Client.get_data(relative_url=self.relative_url)["total_steps"]
        with tqdm(total=total_steps) as pbar:
            started_at = datetime.now()
            while True:
                if (0 < timeout) and (datetime.now() - started_at) > timedelta(
                    seconds=timeout
                ):
                    raise TimeoutError()

                response = Client.get_data(relative_url=self.relative_url)
                completed_steps = response["completed_steps"]

                pbar.update(completed_steps)

                if completed_steps == total_steps:
                    break

                sleep(sleep_for)

    def wait(self, sleep_for: Union[int, float] = 1, timeout: int = 0):
        raise NotImplementedError()


# Cell


@patch
def wait(self: ProgressStatus, sleep_for: Union[int, float] = 1, timeout: int = 0):
    """Blocks execution while waiting for remote action to be completed.

    Args:
        sleep_for: The time interval in seconds between successive API calls to ping the server for fetching the completed steps.
        timeout: The maximum time allowed in seconds for the asynchronous call to complete the process. If the timeout
            exceeds and the process is yet to complete, then the progress_bar will be terminated.

    Raises:
        TimeoutError: in case of timeout
    """
    started_at = datetime.now()
    while True:
        if (0 < timeout) and (datetime.now() - started_at) > timedelta(seconds=timeout):
            raise TimeoutError()

        if self.is_ready():
            return

        sleep(sleep_for)


# Cell


@patch
def pull(self: DataSource) -> ProgressStatus:
    """A function to establish the connection with the data source.

    The pull method establishes the connection with the specified `DataSource` and pulls the
    data into the server for further processing. The call to this method is asynchronous and the progress of the connection can be checked
    using the progress bar or the status flag. Please refer to `DataSource` class documentation for more information.

    Returns:
        An instance of `ProgressStatus` class. `ProgressStatus` is a base class for querying status of a remote operation. For more information
        please refer to `ProgressStatus` class documentation.

    Raises:
        ValueError: If the input parameters to the API are invalid.
        ConnectionError: If the server address is invalid or not reachable.

    Below example shows establishing a connection with the s3 bucket:

    ```python

    Client.authenticate()
    data_source_s3 = DataSource.s3(
        uri="s3://test-airt-service/ecommerce_behavior"
    )

    data_source_s3.pull().progress_bar()
    ```
    """
    Client.get_data(relative_url=f"/data/{int(self.id)}/pull")
    return ProgressStatus(relative_url=f"/data/{int(self.id)}")


# Cell


@patch
def head(self: DataSource) -> pd.DataFrame:
    """A function to display the first few records of the data source.

    After successfully pulling the data into the server, the head function can be used
    to display the first few records of the downloaded data.

    Returns:
        A pandas dataframe that displays the first few records of the connected data source.

    Raises:
        ValueError: If the input parameters to the API are invalid.
        ConnectionError: If the server address is invalid or not reachable.

    An example to show the first few records of the data source:

    ```python

    Client.authenticate()
    data_source_s3 = DataSource.s3(
        uri="s3://test-airt-service/ecommerce_behavior"
    )
    data_source_s3.pull().progress_bar()

    data_source_s3.head()
    ```
    """
    response = Client.get_data(relative_url=f"/data/{int(self.id)}/head")
    return pd.DataFrame(response)


# Cell


class Model(ProgressStatus):
    """A class to query the status of the model training, evaluation, and prediction on the remote server.

    A `Model` class is automatically instantiated when the train() method of the `DataSource` class.
    Currently, it is the only way to instantiate the Model class.

    The model is trained on the connected data and tries to predict a specific event in the future.
    For the model training and prediction, we assume the input data includes the following:

    - a column identifying a client client_column (person, car, business, etc.),

    - a column specifying a type of event we will try to predict target_column (buy, checkout, etc.),

    - a timestamp column specifying the time of an occurred event.

    Along with the above mandatory fields, each row in the data might have additional columns of int,
    category, float, or datetime type and they will be used to make predictions more accurate.

    Finally, we need to know how much ahead we wish to make predictions for. That lead time varies
    widely from application to application and can be in minutes for a webshop or even several weeks for a banking product such as a loan.

    As always, the model training and prediction will happen asynchronously and can take a few hours
    based on the size of your dataset.

    The respective status can be viewed by calling the progress_bar() or the status flag available on
    the returned object. For more information, please check the documentation of `DataSource`

    """

    def __init__(self, model_id: int):
        """Constructs a new `Model` instance

        Warning:
            Do not construct this object directly by calling the constructor, please use
            `DataSource.train()` function instead.

        Args:
            model_id: ID of the model in the airt service
        """
        self.model_id = model_id
        ProgressStatus.__init__(self, relative_url=f"/model/{self.model_id}")

    @staticmethod
    def _get_columns() -> list:
        """Returns the list of columns to be added to the DataFrame."""

        return ["id", "created", "total_steps", "completed_steps"]

    @staticmethod
    def ls(offset: Optional[int] = 0, limit: Optional[int] = 100) -> pd.DataFrame:
        """Display the list of available models in airt service.

        Args:
            offset: The number of rows to offset at the beginning of the models
                list from the server.If `None`, then the default value `0` will be used.
            limit: The maximum number of rows to return from the server. If `None`,
                then the default value `100` will be used.

        Returns:
            A pandas dataframe with the list of available models.

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to list the available models:

        ```python
        Model.ls()
        ```
        """

        _ensure_is_instance(offset, int)
        _ensure_is_instance(limit, int)

        models = Client.get_data(relative_url=f"/model/?offset={offset}&limit={limit}")

        columns = Model._get_columns()

        models_df = _generate_df(models, columns)

        return _add_ready_column(models_df)

    @staticmethod
    def details(id: int) -> pd.DataFrame:
        """Return details of a model

        Args:
            id: The id of the model in the airt service.

        Returns:
            A pandas dataframe with the details of the model.

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to get details of a model (id=1) from airt service:

        ```python
        Model.details(id=1)
        ```
        """
        _ensure_is_instance(id, int)

        details = Client.get_data(relative_url=f"/model/{id}")

        additional_cols = [
            "datasource_id",
            "user_id",
            "client_column",
            "target_column",
            "target",
            "predict_after",
            "timestamp_column",
            "error",
            "disabled",
        ]

        columns = Model._get_columns() + additional_cols

        details_df = pd.DataFrame(details, index=[0])[columns]

        return _add_ready_column(details_df)

    @staticmethod
    def delete(id: int) -> pd.DataFrame:
        """Delete a model from airt service

        Args:
            id: The model id in airt service.

        Returns:
            A pandas DataFrame encapsulating the details of the deleted model id.

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to delete a model (id=1) from airt service:

        ```python
        Model.delete(id=1)
        ```
        """
        _ensure_is_instance(id, int)

        models = Client.delete_data(relative_url=f"/model/{id}")

        columns = Model._get_columns()

        models_df = pd.DataFrame(models, index=[0])[columns]

        return _add_ready_column(models_df)

    def predict(self, data_id: Optional[int] = None) -> "Prediction":
        raise NotImplementedError()

    def evaluate(self) -> pd.DataFrame:
        raise NotImplementedError()


# Cell


@patch
def train(
    self: DataSource,
    *,
    client_column: str,
    timestamp_column: Optional[str] = None,
    target_column: str,
    target: str,
    predict_after: timedelta,
) -> Model:
    """A method to train the ML model on the connected `DataSource`.

    This method trains the model for predicting which clients are most likely to have a specified
    event in the future. The call to this method is asynchronous and the progress of the connection
    can be checked using the progress bar method or the status flag attribute available in the `DataSource` class.
    For more information on the model, please check the documentation of `Model` class.

    Args:
        client_column: The name of the column that uniquely identifies the users/clients as string.
        timestamp_column: Name of the timestamp_column specifying the time of an
            occurred event as a string. If the value is not passed then the None will be
        target_column: Name of the target column that captures the type of event as string. This will
            be used for training the model as well as for making predictions for our target event.
        target: Name of the target event for which the model needs to be trained to make predictions.
            You can pass regular expressions as well to this parameter for making predictions for more than one event.
            For example, the passing `*checkout` will train a model to predict which users will do any kind of a
            checkout event.
        predict_after: Time delta in hours of the expected target event mentioned as timedelta.

    Returns:
        An instance of the `Model` class.

    Raises:
        ValueError: If any of the required parameters are empty or None.
        ValueError: If the input parameters to the API are invalid.
        ConnectionError: If the server address is invalid or not reachable.

    Below is an example for training a model to predict which users will perform a purchase event (`*purchase`) 3 hours before they acctually do it:

    ```python
    from datetime import timedelta

    model = data_source_s3.train(
        client_column="user_id",
        target_column="event_type",
        target="*purchase",
        predict_after=timedelta(hours=3)
    )

    model.progress_bar()
    ```
    """
    _ensure_is_instance(predict_after, timedelta)
    _ensure_is_instance(client_column, str)
    _ensure_is_instance(target_column, str)
    _ensure_is_instance(target, str)

    response = Client.post_data(
        relative_url=f"/model/train",
        data=dict(
            data_id=int(self.id),
            client_column=client_column,
            target_column=str(target_column),
            target=str(target),
            predict_after=int(predict_after.total_seconds()),
        ),
    )
    return Model(model_id=response["id"])


# Cell


class Prediction(ProgressStatus):
    """A class to run predictions on the data source.

    The `Predict` class is automatically instantiated by calling the `train` method of a `Client` instance.
    Currently, it is the only way to instantiate this class. The returned object will have utility methods like converting the prediction
    results into a pandas dataframe and pushing the prediction results into one of the supported data sources etc.,

    For more information on the supported data sources, please refer to the documentation on `DataSource` class
    """

    def __init__(self, prediction_id: int, datasource_id: Optional[int] = None):
        """Constructs a new `Prediction` instance

        Warning:
            Do not construct this object directly by calling the constructor, please use
            `Model.predict()` function instead.

        Args:
            prediction_id: ID of the prediction in the airt service
            datasource_id: The data ID used for running the prediction
        """
        self.prediction_id = prediction_id
        self.datasource_id = datasource_id
        ProgressStatus.__init__(self, relative_url=f"/prediction/{self.prediction_id}")

    def push(self, data_source: DataSource) -> Dict[str, int]:
        """A function to push the prediction results into the target data source.

        For more information on the supported data sources, please refer to the documentation on `DataSource` class

        Args:
            data_source: An instance of the `DataSource` class that encapsulates the data.

        Returns:
            The prediction id and the data id as a dict.

        Raises:
            ValueError: If the input parameters to the API are invalid.
            ConnectionError: If the server address is invalid or not reachable.


        The below example illustrates pushing the prediction results to a database:

        ```python
        from datetime import timedelta

        Client.authenticate()
        data_source_s3 = DataSource.s3(
            uri="s3://test-airt-service/ecommerce_behavior"
        )
        data_source_s3.pull().progress_bar()
        model = data_source_s3.train(
            client_column="user_id",
            target_column="event_type",
            target="*purchase",
            predict_after=timedelta(hours=3),
        )
        data_source_pred = DataSource.s3(
            uri="s3://target-bucket"
        )
        predictions = model.predict()
        predictions.push(data_source_pred)
        ```
        """
        _ensure_is_instance(data_source, DataSource)
        return Client.post_data(
            relative_url=f"/prediction/{self.prediction_id}/push",
            data=dict(data_id=data_source.id),
        )

    @staticmethod
    def _get_columns(col_type: str = "ls_del_cols") -> list:
        """Returns the list of columns to be added to the DataFrame."""

        return ["id", "created", "total_steps", "completed_steps"]

    @staticmethod
    def ls(offset: Optional[int] = 0, limit: Optional[int] = 100) -> pd.DataFrame:
        """Display the list of available predictions in airt service.

        Args:
            offset: The number of rows to offset at the beginning of the predictions
                list from the server.If `None`, then the default value `0` will be used.
            limit: The maximum number of rows to return from the server. If `None`,
                then the default value `100` will be used.

        Returns:
            A pandas dataframe with the list of available predictions.

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to list the available predictions:

        ```python
        Prediction.ls()
        ```
        """

        _ensure_is_instance(offset, int)
        _ensure_is_instance(limit, int)

        predictions = Client.get_data(
            relative_url=f"/prediction/?offset={offset}&limit={limit}"
        )

        columns = Prediction._get_columns()

        predictions_df = _generate_df(predictions, columns)

        return _add_ready_column(predictions_df)

    @staticmethod
    def details(id: int) -> pd.DataFrame:
        """Return details of a prediction

        Args:
            id: The id of the prediction in the airt service.

        Returns:
            A pandas dataframe with the details of the prediction.

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to get details of a prediction (id=1) from airt service:

        ```python
        Prediction.details(id=1)
        ```
        """
        _ensure_is_instance(id, int)

        details = Client.get_data(relative_url=f"/prediction/{id}")

        additional_cols = ["model_id", "datasource_id", "error"]

        columns = Prediction._get_columns() + additional_cols

        details_df = pd.DataFrame(details, index=[0])[columns]

        return _add_ready_column(details_df)

    @staticmethod
    def delete(id: int) -> pd.DataFrame:
        """Delete a prediction from airt service

        Args:
            id: The prediction id in airt service.

        Returns:
            A pandas DataFrame encapsulating the details of the deleted prediction id.

        Raises:
            ConnectionError: If the server address is invalid or not reachable.

        An example to delete a prediction (id=1) from airt service:

        ```python
        Prediction.delete(id=1)
        ```
        """
        _ensure_is_instance(id, int)

        predictions = Client.delete_data(relative_url=f"/prediction/{id}")

        columns = Prediction._get_columns()

        predictions_df = pd.DataFrame(predictions, index=[0])[columns]

        return _add_ready_column(predictions_df)

    def to_pandas(self) -> pd.DataFrame:
        raise NotImplementedError()


# Cell


@patch
def evaluate(self: Model) -> pd.DataFrame:
    """A function to evaluate the performance of the trained model.

    This function returns the performance metrics like accuracy, precision, and recall. Currently,
    the function returns only the above-mentioned metrics and we plan to add more performance metrics in the future.

    Returns:
        A pandas Series that has the performance metrics of the trained model.

    Raises:
        ValueError: If the input parameters to the API are invalid.
        ConnectionError: If the server address is invalid or not reachable.
    """
    model_evaluate = Client.get_data(relative_url=f"/model/{self.model_id}/evaluate")
    return pd.DataFrame(dict(model_evaluate), index=[0]).T.rename(columns={0: "eval"})


# Cell


@patch
def predict(self: Model, data_id: Optional[int] = None) -> "Prediction":
    """A function that uses the trained model and makes predictions.

    As always, this function is asynchronous and can take a few hours based on the size of your dataset. The status of
    the model prediction can be viewed interactively by calling the `progress_bar` method available on the returned object.
    For more information, please check the documentation of `DataSource`

    Args:
        data_id: The data id for running the predictions. If the value is not passed then the data id used for
            training will be used for prediction aswell.
    Returns:
        An instance of the `Prediction` class. For more information on the methods that are available in
        the returned object, please check the documentation of the `Prediction` class

    Raises:
        ValueError: If the input parameters to the API are invalid.
        ConnectionError: If the server address is invalid or not reachable.
    """

    request_body = dict(data_id=data_id) if data_id else None

    response = Client.post_data(
        relative_url=f"/model/{self.model_id}/predict", data=request_body
    )

    return Prediction(
        prediction_id=response["id"], datasource_id=response["datasource_id"]
    )


# Cell


@patch
def to_pandas(self: Prediction) -> pd.DataFrame:
    """A function to convert the predicted results into a Pandas DataFrame object.

    Returns:
        A Pandas DataFrame that contains the prediction results from the model.

    Raises:
        ValueError: If the input parameters to the API are invalid.
        ConnectionError: If the server address is invalid or not reachable.

    The below example illustrates the usage of to_pandas function:

    ```python
    from datetime import timedelta

    Client.authenticate()
    data_source_s3 = DataSource.s3(
        uri="s3://test-airt-service/ecommerce_behavior"
    )
    data_source_s3.pull().progress_bar()
    model = data_source_s3.train(
        client_column="user_id",
        target_column="event_type",
        target="*purchase",
        predict_after=timedelta(hours=3),
    )

    predictions = model.predict()
    predictions.to_pandas()
    ```
    """
    response = Client.get_data(relative_url=f"/prediction/{self.prediction_id}/pandas")
    keys = list(response.keys())
    keys.remove("Score")
    index_name = keys[0]
    return (
        pd.DataFrame(response)
        .set_index(index_name)
        .sort_values("Score", ascending=False)
    )


# Cell


@patch
def push(self: DataSource, predictions: Prediction) -> Dict[str, int]:
    """A function to push the prediction results into the target data source.

    For more information on the supported data sources, please refer to the documentation on `DataSource` class.

    Args:
        predictions: An instance of the `Prediction` class.

    Returns:
            The prediction id and the data id as a dict.

    Raises:
        ValueError: If the input parameters to the API are invalid.
        ConnectionError: If the server address is invalid or not reachable.

    The below example illustrates pushing the prediction results to a database:

    ```python
    from datetime import timedelta

    Client.authenticate()
    data_source_s3 = DataSource.s3(
        uri="s3://test-airt-service/ecommerce_behavior"
    )
    data_source_s3.pull().progress_bar()
    model = data_source_s3.train(
        client_column="user_id",
        target_column="event_type",
        target="*purchase",
        predict_after=timedelta(hours=3),
    )
    data_source_pred = DataSource.s3(
        uri="s3://target-bucket"
    )
    predictions = model.predict()
    data_source_pred.push(predictions)
    ```
    """
    return predictions.push(data_source=self)
